{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoHe1R/9BNXw6ozYONLx2v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salilp42/salilp42.github.io/blob/master/Deep_Autoencoder_PD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amcEitgyTHsD"
      },
      "outputs": [],
      "source": [
        "# First, we need to install the necessary packages\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "\n",
        "# Import the necessary modules\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "\n",
        "# Define the input shape and number of filters for the convolutional layers\n",
        "input_shape = (256, 256, 1) # assuming the saccadic trajectories are 256x256 grayscale images\n",
        "num_filters = 32\n",
        "\n",
        "# Define the input layer\n",
        "input_img = Input(shape=input_shape)\n",
        "\n",
        "# Define the encoder layers\n",
        "x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Define the encoding layer with L1 regularization\n",
        "encoding_layer = Dense(32, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
        "\n",
        "# Define the decoder layers\n",
        "x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(encoding_layer)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the encoder model\n",
        "encoder = Model(input_img, encoding_layer)\n",
        "\n",
        "# Use the encoder model to generate input for classifiers\n",
        "encoded_imgs = encoder.predict(X_train)\n",
        "\n",
        "# Now we can train a classifier using the encoded images and supervised labels\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(encoded_imgs, y_train)\n"
      ]
    }
  ]
}